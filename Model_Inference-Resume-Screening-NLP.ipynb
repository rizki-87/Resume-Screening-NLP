{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNZiU2KJrbnUtfvRMVCgD2d"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# X. Model Inference"],"metadata":{"id":"fok2hjrwbBcF"}},{"cell_type":"markdown","source":["## Import Libraries"],"metadata":{"id":"aZ9opcc5bIxG"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2oaSkkPhQWjL","executionInfo":{"status":"ok","timestamp":1706178999586,"user_tz":-420,"elapsed":10067,"user":{"displayName":"Rizki Aditama","userId":"09155638556336461601"}},"outputId":"e61f051b-dddc-44b3-adcb-f28acd02b6c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (0.3.7)\n"]}],"source":["# Used for data manipulation and analysis\n","import pandas as pd\n","# Provides support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays\n","import numpy as np\n","\n","# Implements binary protocols for serializing and de-serializing a Python object structure\n","import pickle\n","# Installs the dill module, which extends Python's pickle module for serializing and de-serializing Python objects\n","!pip install dill\n","#  Used for serializing and de-serializing Python objects, especially those containing more complex data types\n","import dill\n","# Provides regular expression matching operations similar to those found in Perl\n","import re\n","\n","\n","\n"]},{"cell_type":"markdown","source":["## Prediction System"],"metadata":{"id":"YQQYXUjLi9xN"}},{"cell_type":"markdown","source":["I will try the performance of the model, by entering the CV of a data scientist by copy-pasting..."],"metadata":{"id":"7BQkZz4zb3IE"}},{"cell_type":"code","source":["sampleresume =\"\"\"I am a data scientist specializing in machine\n","learning, deep learning, and computer vision. With\n","a strong background in mathematics, statistics,\n","and programming, I am passionate about\n","uncovering hidden patterns and insights in data.\n","I have extensive experience in developing\n","predictive models, implementing deep learning\n","algorithms, and designing computer vision\n","systems. My technical skills include proficiency in\n","Python, Sklearn, TensorFlow, and PyTorch.\n","What sets me apart is my ability to effectively\n","communicate complex concepts to diverse\n","audiences. I excel in translating technical insights\n","into actionable recommendations that drive\n","informed decision-making.\n","If you're looking for a dedicated and versatile data\n","scientist to collaborate on impactful projects, I am\n","eager to contribute my expertise. Let's harness the\n","power of data together to unlock new possibilities\n","and shape a better future.\n","Contact & Sources\n","Email: 611noorsaeed@gmail.com\n","Phone: 03442826192\n","Github: https://github.com/611noorsaeed\n","Linkdin: https://www.linkedin.com/in/noor-saeed654a23263/\n","Blogs: https://medium.com/@611noorsaeed\n","Youtube: Artificial Intelligence\n","ABOUT ME\n","WORK EXPERIENCE\n","SKILLES\n","NOOR SAEED\n","LANGUAGES\n","English\n","Urdu\n","Hindi\n","I am a versatile data scientist with expertise in a wide\n","range of projects, including machine learning,\n","recommendation systems, deep learning, and computer\n","vision. Throughout my career, I have successfully\n","developed and deployed various machine learning models\n","to solve complex problems and drive data-driven\n","decision-making\n","Machine Learnine\n","Deep Learning\n","Computer Vision\n","Recommendation Systems\n","Data Visualization\n","Programming Languages (Python, SQL)\n","Data Preprocessing and Feature Engineering\n","Model Evaluation and Deployment\n","Statistical Analysis\n","Communication and Collaboration\n","\"\"\""],"metadata":{"id":"AjDMgXzmS9Il"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the trained classifier\n","clf = pickle.load(open('clf.pkl', 'rb'))\n","tfidfd = pickle.load(open('tfidfd.pkl', 'rb'))\n","with open('cleanResume_function.dill', 'rb') as file:\n","    cleanResume = dill.load(file)\n","\n","# Clean the input resume\n","cleaned_resume = cleanResume(sampleresume)\n","\n","# Transform the cleaned resume using the trained TfidfVectorizer\n","input_features = tfidfd.transform([cleaned_resume])\n","\n","# Make the prediction using the loaded classifier\n","prediction_id = clf.predict(input_features)[0]\n","\n","# Map category ID to category name\n","category_mapping = {\n","    15: \"Java Developer\",\n","    23: \"Testing\",\n","    8: \"DevOps Engineer\",\n","    20: \"Python Developer\",\n","    24: \"Web Designing\",\n","    12: \"HR\",\n","    13: \"Hadoop\",\n","    3: \"Blockchain\",\n","    10: \"ETL Developer\",\n","    18: \"Operations Manager\",\n","    6: \"Data Science\",\n","    22: \"Sales\",\n","    16: \"Mechanical Engineer\",\n","    1: \"Arts\",\n","    7: \"Database\",\n","    11: \"Electrical Engineering\",\n","    14: \"Health and fitness\",\n","    19: \"PMO\",\n","    4: \"Business Analyst\",\n","    9: \"DotNet Developer\",\n","    2: \"Automation Testing\",\n","    17: \"Network Security Engineer\",\n","    21: \"SAP Developer\",\n","    5: \"Civil Engineer\",\n","    0: \"Advocate\",\n","}\n","\n","category_name = category_mapping.get(prediction_id, \"Unknown\")\n","\n","print(\"Predicted Category:\", category_name)\n","print(prediction_id)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ooP23BmUKJo","executionInfo":{"status":"ok","timestamp":1706179001210,"user_tz":-420,"elapsed":1647,"user":{"displayName":"Rizki Aditama","userId":"09155638556336461601"}},"outputId":"9aaf1b29-5ee7-43dd-be90-1d6d0aef968f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Category: Data Science\n","6\n"]}]},{"cell_type":"markdown","source":["The results are accurate!"],"metadata":{"id":"fDJ_Tld_cGED"}},{"cell_type":"markdown","source":["## XI. Conclusion\n","\n","In conclusion, this project successfully achieved its primary objective of developing an automated system for analyzing and classifying resumes with a high level of accuracy. The project aimed to address the challenges faced by human resource departments and recruiters in efficiently screening resumes and identifying the most qualified candidates. Leveraging Natural Language Processing (NLP) and machine learning techniques, the project utilized a unique dataset provided by a major IT company based in London.\n","\n","The project methodology involved advanced NLP techniques for data preprocessing and feature extraction. It employed the K-Nearest Neighbors (KNN) classifier and the One-vs-Rest (OvR) strategy for multi-class classification, chosen for their effectiveness in handling text data and accurately classifying resumes into various job categories. The TF-IDF vectorization transformed textual data into a format suitable for machine learning models, enhancing the model's ability to understand and prioritize the relevance of different terms in the resumes.\n","\n","With an accuracy score of approximately 98.45%, the developed classification model demonstrated its robustness in accurately categorizing resumes. The text preprocessing steps, including cleaning, TF-IDF vectorization, and label encoding, improved data quality and prepared the data effectively for model training. The project also emphasized the importance of model storage and code reuse by saving the model and preprocessing function into files.\n","\n","Looking ahead, there are several avenues for further development, including evaluating alternative models, fine-tuning hyperparameters, implementing cross-validation for model validation, conducting in-depth analysis within specific resume categories, expanding the dataset for improved model performance, refining preprocessing steps, and enhancing model interpretability.\n","\n","In summary, this project represents an intersection of technology and human resource management, offering a solution to revolutionize the resume screening and recruitment process. The automated system not only promises increased efficiency but also supports a more inclusive and unbiased approach to candidate selection, contributing valuable insights derived from a dataset provided by a leading IT firm in London.\n","\n","\n","\n","\n","\n"],"metadata":{"id":"YE9OYd0QcUZn"}}]}